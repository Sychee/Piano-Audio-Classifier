{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ###\n",
    "        self._body = nn.Sequential(\n",
    "        # First convolution layer\n",
    "        # input size = (32, 32), output size = (30, 30)\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        \n",
    "        # Second convolution layer\n",
    "        # input size = (15, 15), output size = (12, 12)\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        # output size = (6, 6)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        )  \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        # First fully connected layer\n",
    "        nn.Linear(in_features=92, out_features=120),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        # Second fully connected layer\n",
    "        nn.Linear(in_features=120, out_features=84),\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        # Output Layer\n",
    "        nn.Linear(in_features=84, out_features=7895)\n",
    "        )\n",
    "        ###\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ###\n",
    "        #x = self._body(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        ###\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioNet(\n",
      "  (_body): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "  )\n",
      "  (_head): Sequential(\n",
      "    (0): Linear(in_features=92, out_features=120, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=84, out_features=7895, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "audioNet_model = AudioNet()\n",
    "print(audioNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root, num_workers=4):\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # train dataloader\n",
    "    \n",
    "    train_data_path = os.path.join(data_root, 'train', 'train')\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(root=train_data_path, transform=preprocess),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # test dataloader\n",
    "    \n",
    "    test_data_path = os.path.join(data_root, 'validation', 'validation')\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(root=test_data_path, transform=preprocess),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 16  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 2  # number of times the whole dataset will be passed through the network\n",
    "    learning_rate: float = 0.1  # determines the speed of network's weights update\n",
    "        \n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"/Users/gbanuru/PycharmProjects/HACKUCI/msmd/tutorials/data_root\"  # folder to read/save data\n",
    "    num_workers: int = 10  # number of concurrent processes using to prepare data\n",
    "    device: str = 'cuda'  # device to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:              \n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='audionet_model.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers_to_set = 2\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=training_configuration.batch_size,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "\n",
    "    # initiate model\n",
    "    model = AudioNet()\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=training_configuration.learning_rate\n",
    "    )\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print('Loss decreases, saving the model.\\n')\n",
    "                save_model(model, device)\n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [1600/88012] Loss: 8.958856 Acc: 0.0625\n",
      "Train Epoch: 0 [3200/88012] Loss: 8.971678 Acc: 0.0000\n",
      "Train Epoch: 0 [4800/88012] Loss: 9.001030 Acc: 0.0000\n",
      "Train Epoch: 0 [6400/88012] Loss: 8.928567 Acc: 0.0000\n",
      "Train Epoch: 0 [8000/88012] Loss: 8.946198 Acc: 0.0000\n",
      "Train Epoch: 0 [9600/88012] Loss: 8.876394 Acc: 0.0000\n",
      "Train Epoch: 0 [11200/88012] Loss: 8.784081 Acc: 0.0000\n",
      "Train Epoch: 0 [12800/88012] Loss: 8.400196 Acc: 0.0000\n",
      "Train Epoch: 0 [14400/88012] Loss: 8.468591 Acc: 0.0000\n",
      "Train Epoch: 0 [16000/88012] Loss: 8.648734 Acc: 0.0000\n",
      "Train Epoch: 0 [17600/88012] Loss: 8.296996 Acc: 0.0000\n",
      "Train Epoch: 0 [19200/88012] Loss: 8.893991 Acc: 0.0000\n",
      "Train Epoch: 0 [20800/88012] Loss: 7.830263 Acc: 0.0000\n",
      "Train Epoch: 0 [22400/88012] Loss: 8.081038 Acc: 0.0625\n",
      "Train Epoch: 0 [24000/88012] Loss: 8.344698 Acc: 0.0000\n",
      "Train Epoch: 0 [25600/88012] Loss: 8.797669 Acc: 0.0000\n",
      "Train Epoch: 0 [27200/88012] Loss: 8.307134 Acc: 0.0000\n",
      "Train Epoch: 0 [28800/88012] Loss: 8.566038 Acc: 0.0000\n",
      "Train Epoch: 0 [30400/88012] Loss: 7.678162 Acc: 0.0000\n",
      "Train Epoch: 0 [32000/88012] Loss: 9.106203 Acc: 0.0000\n",
      "Train Epoch: 0 [33600/88012] Loss: 8.111531 Acc: 0.0625\n",
      "Train Epoch: 0 [35200/88012] Loss: 8.037126 Acc: 0.0000\n",
      "Train Epoch: 0 [36800/88012] Loss: 7.786630 Acc: 0.0625\n",
      "Train Epoch: 0 [38400/88012] Loss: 8.162686 Acc: 0.0000\n",
      "Train Epoch: 0 [40000/88012] Loss: 8.466621 Acc: 0.0000\n",
      "Train Epoch: 0 [41600/88012] Loss: 8.046906 Acc: 0.0000\n",
      "Train Epoch: 0 [43200/88012] Loss: 8.706506 Acc: 0.0000\n",
      "Train Epoch: 0 [44800/88012] Loss: 7.855993 Acc: 0.1250\n",
      "Train Epoch: 0 [46400/88012] Loss: 8.532122 Acc: 0.0000\n",
      "Train Epoch: 0 [48000/88012] Loss: 8.197637 Acc: 0.0000\n",
      "Train Epoch: 0 [49600/88012] Loss: 7.836384 Acc: 0.0000\n",
      "Train Epoch: 0 [51200/88012] Loss: 6.987336 Acc: 0.1250\n",
      "Train Epoch: 0 [52800/88012] Loss: 7.994072 Acc: 0.0000\n",
      "Train Epoch: 0 [54400/88012] Loss: 8.106075 Acc: 0.0000\n",
      "Train Epoch: 0 [56000/88012] Loss: 7.260458 Acc: 0.0000\n",
      "Train Epoch: 0 [57600/88012] Loss: 8.392011 Acc: 0.0000\n",
      "Train Epoch: 0 [59200/88012] Loss: 7.536166 Acc: 0.0625\n",
      "Train Epoch: 0 [60800/88012] Loss: 7.666007 Acc: 0.0000\n",
      "Train Epoch: 0 [62400/88012] Loss: 8.428786 Acc: 0.0000\n",
      "Train Epoch: 0 [64000/88012] Loss: 8.050896 Acc: 0.0000\n",
      "Train Epoch: 0 [65600/88012] Loss: 8.616898 Acc: 0.0000\n",
      "Train Epoch: 0 [67200/88012] Loss: 7.976831 Acc: 0.0625\n",
      "Train Epoch: 0 [68800/88012] Loss: 7.684013 Acc: 0.0625\n",
      "Train Epoch: 0 [70400/88012] Loss: 7.975443 Acc: 0.0000\n",
      "Train Epoch: 0 [72000/88012] Loss: 8.346107 Acc: 0.0000\n",
      "Train Epoch: 0 [73600/88012] Loss: 7.423511 Acc: 0.0625\n",
      "Train Epoch: 0 [75200/88012] Loss: 8.604982 Acc: 0.0625\n",
      "Train Epoch: 0 [76800/88012] Loss: 6.604050 Acc: 0.0000\n",
      "Train Epoch: 0 [78400/88012] Loss: 7.470513 Acc: 0.0625\n",
      "Train Epoch: 0 [80000/88012] Loss: 7.235266 Acc: 0.0000\n",
      "Train Epoch: 0 [81600/88012] Loss: 6.310728 Acc: 0.0625\n",
      "Train Epoch: 0 [83200/88012] Loss: 7.970564 Acc: 0.0000\n",
      "Train Epoch: 0 [84800/88012] Loss: 6.900061 Acc: 0.0000\n",
      "Train Epoch: 0 [86400/88012] Loss: 7.022657 Acc: 0.0625\n",
      "Train Epoch: 0 [66000/88012] Loss: 8.719445 Acc: 0.0000\n",
      "Elapsed 29.17s, 29.17 s/epoch, 0.01 s/batch, ets 29.17s\n",
      "\n",
      "Test set: Average loss: 7.1180, Accuracy: 1424/27539 (5%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 1 [1600/88012] Loss: 8.226690 Acc: 0.0000\n",
      "Train Epoch: 1 [3200/88012] Loss: 7.284648 Acc: 0.0625\n",
      "Train Epoch: 1 [4800/88012] Loss: 7.377294 Acc: 0.0000\n",
      "Train Epoch: 1 [6400/88012] Loss: 7.181497 Acc: 0.0625\n",
      "Train Epoch: 1 [8000/88012] Loss: 7.367765 Acc: 0.0000\n",
      "Train Epoch: 1 [9600/88012] Loss: 6.650560 Acc: 0.1250\n",
      "Train Epoch: 1 [11200/88012] Loss: 7.577631 Acc: 0.0000\n",
      "Train Epoch: 1 [12800/88012] Loss: 6.547276 Acc: 0.1250\n",
      "Train Epoch: 1 [14400/88012] Loss: 6.288647 Acc: 0.0625\n",
      "Train Epoch: 1 [16000/88012] Loss: 5.811201 Acc: 0.1250\n",
      "Train Epoch: 1 [17600/88012] Loss: 7.316809 Acc: 0.0625\n",
      "Train Epoch: 1 [19200/88012] Loss: 6.923553 Acc: 0.0625\n",
      "Train Epoch: 1 [20800/88012] Loss: 6.754480 Acc: 0.0625\n",
      "Train Epoch: 1 [22400/88012] Loss: 6.454625 Acc: 0.0625\n",
      "Train Epoch: 1 [24000/88012] Loss: 6.437127 Acc: 0.1250\n",
      "Train Epoch: 1 [25600/88012] Loss: 6.316917 Acc: 0.0625\n",
      "Train Epoch: 1 [27200/88012] Loss: 7.421202 Acc: 0.0000\n",
      "Train Epoch: 1 [28800/88012] Loss: 6.853521 Acc: 0.0625\n",
      "Train Epoch: 1 [30400/88012] Loss: 6.380408 Acc: 0.0625\n",
      "Train Epoch: 1 [32000/88012] Loss: 6.212345 Acc: 0.1250\n",
      "Train Epoch: 1 [33600/88012] Loss: 5.727656 Acc: 0.1875\n",
      "Train Epoch: 1 [35200/88012] Loss: 6.120019 Acc: 0.1875\n",
      "Train Epoch: 1 [36800/88012] Loss: 5.508562 Acc: 0.0625\n",
      "Train Epoch: 1 [38400/88012] Loss: 5.810346 Acc: 0.0625\n",
      "Train Epoch: 1 [40000/88012] Loss: 7.183712 Acc: 0.0000\n",
      "Train Epoch: 1 [41600/88012] Loss: 6.425406 Acc: 0.1250\n",
      "Train Epoch: 1 [43200/88012] Loss: 6.228375 Acc: 0.1875\n",
      "Train Epoch: 1 [44800/88012] Loss: 6.211646 Acc: 0.0000\n",
      "Train Epoch: 1 [46400/88012] Loss: 6.761108 Acc: 0.0625\n",
      "Train Epoch: 1 [48000/88012] Loss: 6.606017 Acc: 0.0625\n",
      "Train Epoch: 1 [49600/88012] Loss: 7.209023 Acc: 0.0625\n",
      "Train Epoch: 1 [51200/88012] Loss: 6.523721 Acc: 0.1875\n",
      "Train Epoch: 1 [52800/88012] Loss: 6.236876 Acc: 0.1250\n",
      "Train Epoch: 1 [54400/88012] Loss: 5.830639 Acc: 0.1250\n",
      "Train Epoch: 1 [56000/88012] Loss: 7.095011 Acc: 0.0625\n",
      "Train Epoch: 1 [57600/88012] Loss: 6.061100 Acc: 0.0625\n",
      "Train Epoch: 1 [59200/88012] Loss: 6.379220 Acc: 0.0000\n",
      "Train Epoch: 1 [60800/88012] Loss: 5.263445 Acc: 0.1250\n",
      "Train Epoch: 1 [62400/88012] Loss: 5.950185 Acc: 0.1250\n",
      "Train Epoch: 1 [64000/88012] Loss: 5.771109 Acc: 0.1250\n",
      "Train Epoch: 1 [65600/88012] Loss: 5.392002 Acc: 0.1250\n",
      "Train Epoch: 1 [67200/88012] Loss: 4.880352 Acc: 0.0625\n",
      "Train Epoch: 1 [68800/88012] Loss: 5.534345 Acc: 0.1875\n",
      "Train Epoch: 1 [70400/88012] Loss: 5.226708 Acc: 0.0625\n",
      "Train Epoch: 1 [72000/88012] Loss: 5.651063 Acc: 0.0625\n",
      "Train Epoch: 1 [73600/88012] Loss: 5.842298 Acc: 0.0000\n",
      "Train Epoch: 1 [75200/88012] Loss: 6.258938 Acc: 0.1250\n",
      "Train Epoch: 1 [76800/88012] Loss: 5.318676 Acc: 0.0625\n",
      "Train Epoch: 1 [78400/88012] Loss: 6.021034 Acc: 0.0625\n",
      "Train Epoch: 1 [80000/88012] Loss: 5.826534 Acc: 0.1875\n",
      "Train Epoch: 1 [81600/88012] Loss: 5.676330 Acc: 0.1250\n",
      "Train Epoch: 1 [83200/88012] Loss: 4.999063 Acc: 0.3125\n",
      "Train Epoch: 1 [84800/88012] Loss: 6.267451 Acc: 0.0625\n",
      "Train Epoch: 1 [86400/88012] Loss: 5.933000 Acc: 0.3750\n",
      "Train Epoch: 1 [66000/88012] Loss: 4.352899 Acc: 0.3333\n",
      "Elapsed 67.40s, 33.70 s/epoch, 0.01 s/batch, ets 0.00s\n",
      "\n",
      "Test set: Average loss: 4.8580, Accuracy: 4794/27539 (17%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Total time: 75.42, Best Loss: 4.858\n"
     ]
    }
   ],
   "source": [
    "if required_training:\n",
    "    model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_loss, color='r', label=\"train loss\")\n",
    "plt.plot(x, epoch_test_loss, color='b', label=\"validation loss\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
