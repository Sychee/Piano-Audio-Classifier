{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ### self._body NOT USED\n",
    "        self._body = nn.Sequential(\n",
    "        # First convolution layer\n",
    "        # input size = (32, 32), output size = (30, 30)\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        \n",
    "        # Second convolution layer\n",
    "        # input size = (15, 15), output size = (12, 12)\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        # output size = (6, 6)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        )  \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        # First fully connected layer\n",
    "        nn.Linear(in_features=92, out_features=120),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        # Second fully connected layer\n",
    "        nn.Linear(in_features=120, out_features=84),\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        # Output Layer\n",
    "        nn.Linear(in_features=84, out_features=35531)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self._body(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioNet(\n",
      "  (_body): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "  )\n",
      "  (_head): Sequential(\n",
      "    (0): Linear(in_features=92, out_features=120, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=84, out_features=35531, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "audioNet_model = AudioNet()\n",
    "print(audioNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root, num_workers=4, subset = True):\n",
    "    \n",
    "    preprocess = transforms.Compose([  # DataLoader loads images with 3 color channels by default\n",
    "    transforms.Grayscale(num_output_channels=1), # convert to one channel image \n",
    "    transforms.ToTensor() # flatten to tensor for AudioNet input\n",
    "    ])\n",
    "    \n",
    "    train_data_path = os.path.join(data_root, 'train', 'train') # train dataloader path\n",
    "    validation_data_path = os.path.join(data_root, 'validation', 'validation') # test dataloader path\n",
    "    \n",
    "    train_data = datasets.ImageFolder(root=train_data_path, transform=preprocess)\n",
    "    validation_data = datasets.ImageFolder(root=validation_data_path, transform=preprocess)\n",
    "    \n",
    "    print(\"Training Data Length\", len(train_data))\n",
    "    print(\"Validation Data Length\", len(validation_data))\n",
    "    \n",
    "    if subset: # use a subset of the data\n",
    "        subset_size = .05 # use 5% of the data\n",
    "        train_data = torch.utils.data.Subset(train_data, np.arange(0, len(train_data), int(1/subset_size)))\n",
    "        validation_data = torch.utils.data.Subset(validation_data, np.arange(0, len(validation_data), int(1/subset_size)))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        validation_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 16  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 10  # number of times the whole dataset will be passed through the network\n",
    "    learning_rate: float = 0.1  # determines the speed of network's weights update\n",
    "        \n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"/Users/gbanuru/PycharmProjects/HACKUCI/msmd/tutorials/data_root\"  # folder to read/save data\n",
    "    num_workers: int = 10  # number of concurrent processes using to prepare data\n",
    "    device: str = 'cuda'  # device to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:              \n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='audionet_model.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers_to_set = 2\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=training_configuration.batch_size,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "\n",
    "    # initiate model\n",
    "    model = AudioNet()\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=training_configuration.learning_rate\n",
    "    )\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print('Loss decreases, saving the model.\\n')\n",
    "                save_model(model, device)\n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Length 906425\n",
      "Validation Data Length 293785\n",
      "Train Epoch: 0 [1600/45322] Loss: 10.441689 Acc: 0.0625\n",
      "Train Epoch: 0 [3200/45322] Loss: 10.468243 Acc: 0.0000\n",
      "Train Epoch: 0 [4800/45322] Loss: 10.514461 Acc: 0.0000\n",
      "Train Epoch: 0 [6400/45322] Loss: 10.284564 Acc: 0.0625\n",
      "Train Epoch: 0 [8000/45322] Loss: 10.458291 Acc: 0.0000\n",
      "Train Epoch: 0 [9600/45322] Loss: 10.158900 Acc: 0.0625\n",
      "Train Epoch: 0 [11200/45322] Loss: 10.243491 Acc: 0.0000\n",
      "Train Epoch: 0 [12800/45322] Loss: 10.141673 Acc: 0.0000\n",
      "Train Epoch: 0 [14400/45322] Loss: 9.611820 Acc: 0.0000\n",
      "Train Epoch: 0 [16000/45322] Loss: 10.227528 Acc: 0.0000\n",
      "Train Epoch: 0 [17600/45322] Loss: 8.714122 Acc: 0.0000\n",
      "Train Epoch: 0 [19200/45322] Loss: 8.033529 Acc: 0.0000\n",
      "Train Epoch: 0 [20800/45322] Loss: 9.375345 Acc: 0.0000\n",
      "Train Epoch: 0 [22400/45322] Loss: 9.889349 Acc: 0.0000\n",
      "Train Epoch: 0 [24000/45322] Loss: 8.497249 Acc: 0.0625\n",
      "Train Epoch: 0 [25600/45322] Loss: 9.597708 Acc: 0.0000\n",
      "Train Epoch: 0 [27200/45322] Loss: 9.347157 Acc: 0.0000\n",
      "Train Epoch: 0 [28800/45322] Loss: 9.860860 Acc: 0.0000\n",
      "Train Epoch: 0 [30400/45322] Loss: 9.499845 Acc: 0.0000\n",
      "Train Epoch: 0 [32000/45322] Loss: 10.184298 Acc: 0.0000\n",
      "Train Epoch: 0 [33600/45322] Loss: 8.478644 Acc: 0.0000\n",
      "Train Epoch: 0 [35200/45322] Loss: 9.142054 Acc: 0.0000\n",
      "Train Epoch: 0 [36800/45322] Loss: 8.980953 Acc: 0.0000\n",
      "Train Epoch: 0 [38400/45322] Loss: 8.867200 Acc: 0.0000\n",
      "Train Epoch: 0 [40000/45322] Loss: 7.969271 Acc: 0.0000\n",
      "Train Epoch: 0 [41600/45322] Loss: 8.861309 Acc: 0.0000\n",
      "Train Epoch: 0 [43200/45322] Loss: 8.343671 Acc: 0.0000\n",
      "Train Epoch: 0 [44800/45322] Loss: 8.707308 Acc: 0.0000\n",
      "Elapsed 48.19s, 48.19 s/epoch, 0.02 s/batch, ets 433.69s\n",
      "\n",
      "Test set: Average loss: 8.9190, Accuracy: 245/14690 (2%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 1 [1600/45322] Loss: 9.743486 Acc: 0.0000\n",
      "Train Epoch: 1 [3200/45322] Loss: 8.940538 Acc: 0.0000\n",
      "Train Epoch: 1 [4800/45322] Loss: 8.278769 Acc: 0.0625\n",
      "Train Epoch: 1 [6400/45322] Loss: 9.083461 Acc: 0.0000\n",
      "Train Epoch: 1 [8000/45322] Loss: 9.587574 Acc: 0.0625\n",
      "Train Epoch: 1 [9600/45322] Loss: 9.231844 Acc: 0.0000\n",
      "Train Epoch: 1 [11200/45322] Loss: 9.126725 Acc: 0.0625\n",
      "Train Epoch: 1 [12800/45322] Loss: 8.638946 Acc: 0.0000\n",
      "Train Epoch: 1 [14400/45322] Loss: 9.578144 Acc: 0.0000\n",
      "Train Epoch: 1 [16000/45322] Loss: 9.805849 Acc: 0.0000\n",
      "Train Epoch: 1 [17600/45322] Loss: 7.946331 Acc: 0.0000\n",
      "Train Epoch: 1 [19200/45322] Loss: 9.230995 Acc: 0.0000\n",
      "Train Epoch: 1 [20800/45322] Loss: 9.574678 Acc: 0.0000\n",
      "Train Epoch: 1 [22400/45322] Loss: 9.310471 Acc: 0.0000\n",
      "Train Epoch: 1 [24000/45322] Loss: 9.335062 Acc: 0.0625\n",
      "Train Epoch: 1 [25600/45322] Loss: 8.267624 Acc: 0.0000\n",
      "Train Epoch: 1 [27200/45322] Loss: 8.010184 Acc: 0.0625\n",
      "Train Epoch: 1 [28800/45322] Loss: 8.553071 Acc: 0.0000\n",
      "Train Epoch: 1 [30400/45322] Loss: 9.520403 Acc: 0.0625\n",
      "Train Epoch: 1 [32000/45322] Loss: 8.645903 Acc: 0.1250\n",
      "Train Epoch: 1 [33600/45322] Loss: 8.143480 Acc: 0.0625\n",
      "Train Epoch: 1 [35200/45322] Loss: 7.660650 Acc: 0.0000\n",
      "Train Epoch: 1 [36800/45322] Loss: 7.728087 Acc: 0.0000\n",
      "Train Epoch: 1 [38400/45322] Loss: 7.740495 Acc: 0.0000\n",
      "Train Epoch: 1 [40000/45322] Loss: 8.650116 Acc: 0.0625\n",
      "Train Epoch: 1 [41600/45322] Loss: 9.010661 Acc: 0.0000\n",
      "Train Epoch: 1 [43200/45322] Loss: 8.625880 Acc: 0.0000\n",
      "Train Epoch: 1 [44800/45322] Loss: 8.717597 Acc: 0.0000\n",
      "Elapsed 100.10s, 50.05 s/epoch, 0.02 s/batch, ets 400.39s\n",
      "\n",
      "Test set: Average loss: 8.2485, Accuracy: 698/14690 (5%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 2 [1600/45322] Loss: 7.881804 Acc: 0.1250\n",
      "Train Epoch: 2 [3200/45322] Loss: 7.907983 Acc: 0.0000\n",
      "Train Epoch: 2 [4800/45322] Loss: 8.427944 Acc: 0.0000\n",
      "Train Epoch: 2 [6400/45322] Loss: 7.702496 Acc: 0.0000\n",
      "Train Epoch: 2 [8000/45322] Loss: 8.469797 Acc: 0.0000\n",
      "Train Epoch: 2 [9600/45322] Loss: 8.045177 Acc: 0.0000\n",
      "Train Epoch: 2 [11200/45322] Loss: 8.651000 Acc: 0.0625\n",
      "Train Epoch: 2 [12800/45322] Loss: 7.581699 Acc: 0.1875\n",
      "Train Epoch: 2 [14400/45322] Loss: 8.536810 Acc: 0.1250\n",
      "Train Epoch: 2 [16000/45322] Loss: 7.485950 Acc: 0.0625\n",
      "Train Epoch: 2 [17600/45322] Loss: 9.162043 Acc: 0.0625\n",
      "Train Epoch: 2 [19200/45322] Loss: 6.725833 Acc: 0.0000\n",
      "Train Epoch: 2 [20800/45322] Loss: 7.232903 Acc: 0.1875\n",
      "Train Epoch: 2 [22400/45322] Loss: 8.081543 Acc: 0.0000\n",
      "Train Epoch: 2 [24000/45322] Loss: 9.251168 Acc: 0.0000\n",
      "Train Epoch: 2 [25600/45322] Loss: 9.452622 Acc: 0.0000\n",
      "Train Epoch: 2 [27200/45322] Loss: 9.562405 Acc: 0.0625\n",
      "Train Epoch: 2 [28800/45322] Loss: 8.968000 Acc: 0.0000\n",
      "Train Epoch: 2 [30400/45322] Loss: 8.334879 Acc: 0.0000\n",
      "Train Epoch: 2 [32000/45322] Loss: 7.085845 Acc: 0.1250\n",
      "Train Epoch: 2 [33600/45322] Loss: 5.861106 Acc: 0.1250\n",
      "Train Epoch: 2 [35200/45322] Loss: 6.819944 Acc: 0.1250\n",
      "Train Epoch: 2 [36800/45322] Loss: 9.198869 Acc: 0.0000\n",
      "Train Epoch: 2 [38400/45322] Loss: 8.727514 Acc: 0.0625\n",
      "Train Epoch: 2 [40000/45322] Loss: 8.838757 Acc: 0.1250\n",
      "Train Epoch: 2 [41600/45322] Loss: 6.257792 Acc: 0.1875\n",
      "Train Epoch: 2 [43200/45322] Loss: 7.725906 Acc: 0.1250\n",
      "Train Epoch: 2 [44800/45322] Loss: 9.064430 Acc: 0.0000\n",
      "Elapsed 150.12s, 50.04 s/epoch, 0.02 s/batch, ets 350.29s\n",
      "\n",
      "Test set: Average loss: 7.4416, Accuracy: 1430/14690 (10%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 3 [1600/45322] Loss: 6.672335 Acc: 0.1250\n",
      "Train Epoch: 3 [3200/45322] Loss: 7.171586 Acc: 0.0000\n",
      "Train Epoch: 3 [4800/45322] Loss: 7.121879 Acc: 0.0000\n",
      "Train Epoch: 3 [6400/45322] Loss: 7.848183 Acc: 0.0625\n",
      "Train Epoch: 3 [8000/45322] Loss: 7.846677 Acc: 0.0000\n",
      "Train Epoch: 3 [9600/45322] Loss: 7.406611 Acc: 0.0625\n",
      "Train Epoch: 3 [11200/45322] Loss: 6.860340 Acc: 0.1250\n",
      "Train Epoch: 3 [12800/45322] Loss: 8.270744 Acc: 0.0000\n",
      "Train Epoch: 3 [14400/45322] Loss: 7.052543 Acc: 0.1875\n",
      "Train Epoch: 3 [16000/45322] Loss: 7.717164 Acc: 0.1250\n",
      "Train Epoch: 3 [17600/45322] Loss: 6.336446 Acc: 0.1250\n",
      "Train Epoch: 3 [19200/45322] Loss: 7.596927 Acc: 0.0625\n",
      "Train Epoch: 3 [20800/45322] Loss: 8.974628 Acc: 0.0625\n",
      "Train Epoch: 3 [22400/45322] Loss: 7.110660 Acc: 0.1250\n",
      "Train Epoch: 3 [24000/45322] Loss: 6.785080 Acc: 0.1875\n",
      "Train Epoch: 3 [25600/45322] Loss: 6.646583 Acc: 0.0625\n",
      "Train Epoch: 3 [27200/45322] Loss: 7.048717 Acc: 0.1875\n",
      "Train Epoch: 3 [28800/45322] Loss: 8.022985 Acc: 0.0625\n",
      "Train Epoch: 3 [30400/45322] Loss: 6.034063 Acc: 0.1250\n",
      "Train Epoch: 3 [32000/45322] Loss: 6.483433 Acc: 0.2500\n",
      "Train Epoch: 3 [33600/45322] Loss: 7.010149 Acc: 0.0625\n",
      "Train Epoch: 3 [35200/45322] Loss: 7.061113 Acc: 0.0625\n",
      "Train Epoch: 3 [36800/45322] Loss: 7.527702 Acc: 0.1250\n",
      "Train Epoch: 3 [38400/45322] Loss: 7.649307 Acc: 0.0625\n",
      "Train Epoch: 3 [40000/45322] Loss: 5.563111 Acc: 0.2500\n",
      "Train Epoch: 3 [41600/45322] Loss: 7.147145 Acc: 0.1875\n",
      "Train Epoch: 3 [43200/45322] Loss: 6.946791 Acc: 0.1250\n",
      "Train Epoch: 3 [44800/45322] Loss: 6.875991 Acc: 0.0000\n",
      "Elapsed 199.13s, 49.78 s/epoch, 0.02 s/batch, ets 298.69s\n",
      "\n",
      "Test set: Average loss: 6.7880, Accuracy: 2006/14690 (14%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 4 [1600/45322] Loss: 6.773682 Acc: 0.1250\n",
      "Train Epoch: 4 [3200/45322] Loss: 5.429278 Acc: 0.2500\n",
      "Train Epoch: 4 [4800/45322] Loss: 5.078495 Acc: 0.3750\n",
      "Train Epoch: 4 [6400/45322] Loss: 6.310865 Acc: 0.1875\n",
      "Train Epoch: 4 [8000/45322] Loss: 5.602467 Acc: 0.1875\n",
      "Train Epoch: 4 [9600/45322] Loss: 8.099532 Acc: 0.0000\n",
      "Train Epoch: 4 [11200/45322] Loss: 6.257978 Acc: 0.2500\n",
      "Train Epoch: 4 [12800/45322] Loss: 6.748497 Acc: 0.0625\n",
      "Train Epoch: 4 [14400/45322] Loss: 7.517418 Acc: 0.0625\n",
      "Train Epoch: 4 [16000/45322] Loss: 6.485728 Acc: 0.0625\n",
      "Train Epoch: 4 [17600/45322] Loss: 5.987682 Acc: 0.1875\n",
      "Train Epoch: 4 [19200/45322] Loss: 6.232164 Acc: 0.1250\n",
      "Train Epoch: 4 [20800/45322] Loss: 7.578675 Acc: 0.1250\n",
      "Train Epoch: 4 [22400/45322] Loss: 6.398147 Acc: 0.0625\n",
      "Train Epoch: 4 [24000/45322] Loss: 6.695690 Acc: 0.0625\n",
      "Train Epoch: 4 [25600/45322] Loss: 6.512619 Acc: 0.1250\n",
      "Train Epoch: 4 [27200/45322] Loss: 5.601711 Acc: 0.1250\n",
      "Train Epoch: 4 [28800/45322] Loss: 7.556737 Acc: 0.0000\n",
      "Train Epoch: 4 [30400/45322] Loss: 5.623874 Acc: 0.3125\n",
      "Train Epoch: 4 [32000/45322] Loss: 6.081144 Acc: 0.1875\n",
      "Train Epoch: 4 [33600/45322] Loss: 7.081445 Acc: 0.0625\n",
      "Train Epoch: 4 [35200/45322] Loss: 5.462140 Acc: 0.1875\n",
      "Train Epoch: 4 [36800/45322] Loss: 4.734852 Acc: 0.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [38400/45322] Loss: 4.913227 Acc: 0.3750\n",
      "Train Epoch: 4 [40000/45322] Loss: 6.462015 Acc: 0.0000\n",
      "Train Epoch: 4 [41600/45322] Loss: 7.158853 Acc: 0.1250\n",
      "Train Epoch: 4 [43200/45322] Loss: 5.936141 Acc: 0.0625\n",
      "Train Epoch: 4 [44800/45322] Loss: 6.173256 Acc: 0.0625\n",
      "Elapsed 252.49s, 50.50 s/epoch, 0.02 s/batch, ets 252.49s\n",
      "\n",
      "Test set: Average loss: 6.2925, Accuracy: 2390/14690 (16%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 5 [1600/45322] Loss: 6.206593 Acc: 0.0625\n",
      "Train Epoch: 5 [3200/45322] Loss: 6.126093 Acc: 0.1875\n",
      "Train Epoch: 5 [4800/45322] Loss: 5.796143 Acc: 0.1875\n",
      "Train Epoch: 5 [6400/45322] Loss: 4.322065 Acc: 0.4375\n",
      "Train Epoch: 5 [8000/45322] Loss: 6.082747 Acc: 0.1250\n",
      "Train Epoch: 5 [9600/45322] Loss: 6.240104 Acc: 0.1250\n",
      "Train Epoch: 5 [11200/45322] Loss: 4.402931 Acc: 0.2500\n",
      "Train Epoch: 5 [12800/45322] Loss: 5.442331 Acc: 0.3750\n",
      "Train Epoch: 5 [14400/45322] Loss: 6.008009 Acc: 0.1875\n",
      "Train Epoch: 5 [16000/45322] Loss: 5.753677 Acc: 0.1875\n",
      "Train Epoch: 5 [17600/45322] Loss: 5.960191 Acc: 0.1250\n",
      "Train Epoch: 5 [19200/45322] Loss: 6.699264 Acc: 0.1875\n",
      "Train Epoch: 5 [20800/45322] Loss: 5.165294 Acc: 0.2500\n",
      "Train Epoch: 5 [22400/45322] Loss: 6.311347 Acc: 0.1250\n",
      "Train Epoch: 5 [24000/45322] Loss: 6.459303 Acc: 0.0625\n",
      "Train Epoch: 5 [25600/45322] Loss: 6.306660 Acc: 0.1250\n",
      "Train Epoch: 5 [27200/45322] Loss: 6.033118 Acc: 0.1875\n",
      "Train Epoch: 5 [28800/45322] Loss: 6.380860 Acc: 0.1875\n",
      "Train Epoch: 5 [30400/45322] Loss: 4.879741 Acc: 0.3125\n",
      "Train Epoch: 5 [32000/45322] Loss: 7.373119 Acc: 0.0625\n",
      "Train Epoch: 5 [33600/45322] Loss: 5.327592 Acc: 0.1250\n",
      "Train Epoch: 5 [35200/45322] Loss: 6.602602 Acc: 0.1250\n",
      "Train Epoch: 5 [36800/45322] Loss: 5.660209 Acc: 0.1875\n",
      "Train Epoch: 5 [38400/45322] Loss: 4.911486 Acc: 0.2500\n",
      "Train Epoch: 5 [40000/45322] Loss: 4.602759 Acc: 0.1875\n",
      "Train Epoch: 5 [41600/45322] Loss: 5.139598 Acc: 0.1250\n",
      "Train Epoch: 5 [43200/45322] Loss: 5.264376 Acc: 0.3125\n",
      "Train Epoch: 5 [44800/45322] Loss: 6.126059 Acc: 0.1250\n",
      "Elapsed 304.94s, 50.82 s/epoch, 0.02 s/batch, ets 203.29s\n",
      "\n",
      "Test set: Average loss: 5.9453, Accuracy: 2690/14690 (18%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 6 [1600/45322] Loss: 5.594703 Acc: 0.1875\n",
      "Train Epoch: 6 [3200/45322] Loss: 3.982820 Acc: 0.4375\n",
      "Train Epoch: 6 [4800/45322] Loss: 5.728331 Acc: 0.0625\n",
      "Train Epoch: 6 [6400/45322] Loss: 4.229818 Acc: 0.3750\n",
      "Train Epoch: 6 [8000/45322] Loss: 6.969785 Acc: 0.0625\n",
      "Train Epoch: 6 [9600/45322] Loss: 5.858488 Acc: 0.0625\n",
      "Train Epoch: 6 [11200/45322] Loss: 5.094924 Acc: 0.1875\n",
      "Train Epoch: 6 [12800/45322] Loss: 5.221766 Acc: 0.1875\n",
      "Train Epoch: 6 [14400/45322] Loss: 4.697035 Acc: 0.3125\n",
      "Train Epoch: 6 [16000/45322] Loss: 5.453127 Acc: 0.1875\n",
      "Train Epoch: 6 [17600/45322] Loss: 5.259768 Acc: 0.1875\n",
      "Train Epoch: 6 [19200/45322] Loss: 5.593894 Acc: 0.1250\n",
      "Train Epoch: 6 [20800/45322] Loss: 4.582677 Acc: 0.3125\n",
      "Train Epoch: 6 [22400/45322] Loss: 4.176939 Acc: 0.1250\n",
      "Train Epoch: 6 [24000/45322] Loss: 4.436645 Acc: 0.3125\n",
      "Train Epoch: 6 [25600/45322] Loss: 5.174344 Acc: 0.0000\n",
      "Train Epoch: 6 [27200/45322] Loss: 5.527285 Acc: 0.2500\n",
      "Train Epoch: 6 [28800/45322] Loss: 6.053257 Acc: 0.1250\n",
      "Train Epoch: 6 [30400/45322] Loss: 4.857817 Acc: 0.4375\n",
      "Train Epoch: 6 [32000/45322] Loss: 4.531492 Acc: 0.3125\n",
      "Train Epoch: 6 [33600/45322] Loss: 6.088175 Acc: 0.0000\n",
      "Train Epoch: 6 [35200/45322] Loss: 5.764379 Acc: 0.1250\n",
      "Train Epoch: 6 [36800/45322] Loss: 5.044387 Acc: 0.3125\n",
      "Train Epoch: 6 [38400/45322] Loss: 5.068440 Acc: 0.3750\n",
      "Train Epoch: 6 [40000/45322] Loss: 4.758112 Acc: 0.1250\n",
      "Train Epoch: 6 [41600/45322] Loss: 5.557188 Acc: 0.1250\n",
      "Train Epoch: 6 [43200/45322] Loss: 4.458687 Acc: 0.3125\n",
      "Train Epoch: 6 [44800/45322] Loss: 6.281174 Acc: 0.1875\n",
      "Elapsed 360.77s, 51.54 s/epoch, 0.02 s/batch, ets 154.61s\n",
      "\n",
      "Test set: Average loss: 5.6883, Accuracy: 2941/14690 (20%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 7 [1600/45322] Loss: 5.198636 Acc: 0.1875\n",
      "Train Epoch: 7 [3200/45322] Loss: 4.433851 Acc: 0.1875\n",
      "Train Epoch: 7 [4800/45322] Loss: 5.873492 Acc: 0.1875\n",
      "Train Epoch: 7 [6400/45322] Loss: 6.079316 Acc: 0.1250\n",
      "Train Epoch: 7 [8000/45322] Loss: 4.023966 Acc: 0.4375\n",
      "Train Epoch: 7 [9600/45322] Loss: 5.215514 Acc: 0.1250\n",
      "Train Epoch: 7 [11200/45322] Loss: 4.254365 Acc: 0.1875\n",
      "Train Epoch: 7 [12800/45322] Loss: 3.959973 Acc: 0.1250\n",
      "Train Epoch: 7 [14400/45322] Loss: 4.219224 Acc: 0.3125\n",
      "Train Epoch: 7 [16000/45322] Loss: 4.461922 Acc: 0.3125\n",
      "Train Epoch: 7 [17600/45322] Loss: 5.480943 Acc: 0.1250\n",
      "Train Epoch: 7 [19200/45322] Loss: 4.810712 Acc: 0.2500\n",
      "Train Epoch: 7 [20800/45322] Loss: 6.109731 Acc: 0.0000\n",
      "Train Epoch: 7 [22400/45322] Loss: 4.989561 Acc: 0.1875\n",
      "Train Epoch: 7 [24000/45322] Loss: 4.771189 Acc: 0.3125\n",
      "Train Epoch: 7 [25600/45322] Loss: 5.283636 Acc: 0.0625\n",
      "Train Epoch: 7 [27200/45322] Loss: 4.615775 Acc: 0.1875\n",
      "Train Epoch: 7 [28800/45322] Loss: 5.466550 Acc: 0.2500\n",
      "Train Epoch: 7 [30400/45322] Loss: 5.508249 Acc: 0.1875\n",
      "Train Epoch: 7 [32000/45322] Loss: 4.797404 Acc: 0.1875\n",
      "Train Epoch: 7 [33600/45322] Loss: 5.442861 Acc: 0.1875\n"
     ]
    }
   ],
   "source": [
    "if required_training:\n",
    "    model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss\n",
    "#plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "#x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "#plt.figure\n",
    "#plt.plot(x, epoch_train_loss, color='r', label=\"train loss\")\n",
    "#plt.plot(x, epoch_test_loss, color='b', label=\"validation loss\")\n",
    "#plt.xlabel('epoch no.')\n",
    "#plt.ylabel('loss')\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.title('Training and Validation Loss')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
