{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect and split data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convFilter\n",
    "import os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countClasses(root, debugContent=False): #counts the classes and number of data from root\n",
    "    class_count = 0\n",
    "    data_count = 0\n",
    "    for dataClass in os.listdir(root):\n",
    "        class_count +=1\n",
    "        for dataItem in os.listdir(root + \"/\" + dataClass):\n",
    "            data_count += 1\n",
    "        \n",
    "        if debugContent:\n",
    "            img = cv2.imread(root + \"/\" + dataClass + \"/\" + dataItem, cv2.IMREAD_GRAYSCALE)\n",
    "            strImg = str(','.join(str(item) for innerlist in img for item in innerlist))\n",
    "            print(\"DataClass: \", dataClass)\n",
    "            print(\"Img String\", strImg)\n",
    "            \n",
    "    print(f\"Total Classes: {class_count}\")\n",
    "    print(f\"Total Data: {data_count}\")\n",
    "\n",
    "def InitiateData(root): #clears all data in root folder\n",
    "    for item in os.listdir(root):\n",
    "        assert item in [\"all\", \"train\", \"validation\", \"test\", \"\"] #safety check to make sure root is correct\n",
    "        shutil.rmtree(os.path.join(root,item)) #clears all items in root\n",
    "    allDir = os.path.join(root, \"all\")\n",
    "    os.mkdir(allDir)\n",
    "    allallDir = os.path.join(allDir, \"all\")\n",
    "    os.mkdir(allallDir) #creates all/all in root dir\n",
    "    \n",
    "def populateData(filtered_performances, root, save=True):\n",
    "    \"\"\"\n",
    "    Slices spectrograms in filtered_performances and saves images in all/all folder with class as folder name\n",
    "    \"\"\"\n",
    "    \n",
    "    if save:\n",
    "        InitiateData(root) #clear data in root folder\n",
    "        \n",
    "    root = os.path.join(root, \"all/all\")\n",
    "    class_count = defaultdict(int)\n",
    "    data_count = 0\n",
    "    for piecenum in range(len(filtered_performances)):\n",
    "        print(f\"Piece {piecenum} of {len(filtered_performances)}\")\n",
    "        \n",
    "        piece = filtered_performances[piecenum]\n",
    "        try:\n",
    "            performance = piece.load_performance(piece.available_performances[0], require_audio=False)\n",
    "            spectrogram = performance.load_spectrogram()\n",
    "        except Exception as e:\n",
    "            print(f\"EXCEPTION at Piece {piecenum}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        slices = spectrogram.shape[1]\n",
    "        for slice in range(slices):\n",
    "            try:\n",
    "                trueVal = str(int(''.join(map(str, convFilter.getNvec(slice, performance))), 2))\n",
    "                if trueVal in class_count:\n",
    "                    class_count[trueVal] += 1\n",
    "                else:\n",
    "                    class_count[trueVal] = 1\n",
    "                data_count += 1\n",
    "                \n",
    "                trueSpec = convFilter.getSpectrogram(slice, performance)\n",
    "                \n",
    "                if save:\n",
    "                    addImageToDirectory(trueSpec, f\"img{class_count[trueVal]}.png\", trueVal, root)\n",
    "                \n",
    "            except IndexError as e:\n",
    "                print(f\"INDEXERROR: PieceNum: {piecenum}, Slice: {slice}, Message: {e}\")    \n",
    "    \n",
    "    print(f\"Total Classes: {len(class_count)}\")\n",
    "    print(f\"Total Data: {data_count}\")\n",
    "            \n",
    "def addImageToDirectory(image, imageName, folder, root):\n",
    "    \"\"\"\n",
    "    Adds image to directory specified\n",
    "    \"\"\"\n",
    "    destDir = os.path.join(root, folder)\n",
    "    if os.path.isdir(destDir):\n",
    "        cv2.imwrite(os.path.join(destDir , imageName), image)\n",
    "    else:\n",
    "        try:  \n",
    "            os.mkdir(destDir)  \n",
    "            cv2.imwrite(os.path.join(destDir , imageName), image)\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "\n",
    "def divideDataIntoTrainValTestSets(root, train=.6, val=.2, test=.2):\n",
    "    \"\"\"\n",
    "    Distributes data into train, validation, and test sets from all/all folder\n",
    "    \"\"\"\n",
    "    allPath = os.path.join(root, \"all/all\")\n",
    "    \n",
    "    assert train + val + test == 1\n",
    "    \n",
    "    split_folders.ratio(allPath, output=root, seed=1337, ratio=(train, val, test)) # default values\n",
    "    os.rename(os.path.join(root, \"val\"), os.path.join(root, \"validation\"))\n",
    "    \n",
    "    temp = \"Temp\"\n",
    "    os.mkdir(os.path.join(root, \"train\" + temp))\n",
    "    os.mkdir(os.path.join(root, \"validation\" + temp))\n",
    "    os.mkdir(os.path.join(root, \"test\" + temp))\n",
    "    \n",
    "    for item in [\"train\", \"validation\", \"test\"]:\n",
    "        dest = shutil.move(os.path.join(root, item), os.path.join(root, item + temp))\n",
    "        os.rename(os.path.join(root, item + temp), os.path.join(root, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbanuru/PycharmProjects/HACKUCI/msmd/msmd/data_model/util.py:30: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  metadata = yaml.load(hdl)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pieces: 601\n",
      "Total Classes: 7895\n",
      "Total Data: 150512\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    DATA_ROOT_MSMD = '/Users/gbanuru/PycharmProjects/HACKUCI/msmd_aug_v1-1_no-audio/' # path to MSMD data set\n",
    "    dataRoot = \"/Users/gbanuru/PycharmProjects/HACKUCI/msmd/tutorials/data_root\" # path to our created dataset\n",
    "    \n",
    "    filtered_performances = convFilter.filteredData(DATA_ROOT_MSMD) #creates a list with piece object\n",
    "    print(f\"All pieces: {len(filtered_performances)}\")\n",
    "    #populateData(filtered_performances[:50], dataRoot, save = False)\n",
    "    #divideDataIntoTrainValTestSets(dataRoot)\n",
    "    countClasses(dataRoot + \"/all/all\")\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
