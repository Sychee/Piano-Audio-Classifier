{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect and split data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convFilter\n",
    "import os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import split_folders\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countClasses(data_root, debugContent=False): #counts the classes and number of data from root\n",
    "    root = os.path.join(data_root, \"all/all\")\n",
    "    class_count = 0\n",
    "    data_count = 0\n",
    "    \n",
    "    for dataClass in os.listdir(root):\n",
    "        class_count +=1\n",
    "        for dataItem in os.listdir(root + \"/\" + dataClass):\n",
    "            data_count += 1\n",
    "        \n",
    "        if debugContent:\n",
    "            img = cv2.imread(root + \"/\" + dataClass + \"/\" + dataItem, cv2.IMREAD_GRAYSCALE)\n",
    "            strImg = str(','.join(str(item) for innerlist in img for item in innerlist))\n",
    "            print(\"DataClass: \", dataClass)\n",
    "            print(\"Img String\", strImg)\n",
    "            \n",
    "    print(f\"Total Classes: {class_count}\")\n",
    "    print(f\"Total Data: {data_count}\")\n",
    "    \n",
    "def initiateData(data_root): #CLEARS ALL DATA IN DATA_ROOT FOLDER\n",
    "    for item in os.listdir(data_root):\n",
    "        assert item in [\"all\", \"train\", \"validation\", \"test\", \"\"] #safety check to make sure root is correct\n",
    "        shutil.rmtree(os.path.join(data_root,item)) #clears all items in root\n",
    "    all_dir = os.path.join(data_root, \"all\")\n",
    "    os.mkdir(all_dir)\n",
    "    all_root = os.path.join(all_dir, \"all\")\n",
    "    os.mkdir(all_root) #creates all/all in root dir\n",
    "    \n",
    "def populateData(filtered_performances, data_root, save=True):\n",
    "    \"\"\"\n",
    "    Slices spectrograms in filtered_performances and saves images in all/all folder with class as folder name\n",
    "    \"\"\"\n",
    "    if save:\n",
    "        initiateData(data_root) #clear data in root folder\n",
    "        \n",
    "    all_root = os.path.join(data_root, \"all/all\")\n",
    "    class_count = defaultdict(int)\n",
    "    data_count = 0\n",
    "    for piecenum in range(len(filtered_performances)):\n",
    "        print(f\"Piece {piecenum} of {len(filtered_performances)}\")\n",
    "        \n",
    "        piece = filtered_performances[piecenum]\n",
    "        try:\n",
    "            performance = piece.load_performance(piece.available_performances[0], require_audio=False)\n",
    "            spectrogram = performance.load_spectrogram()\n",
    "        except Exception as e:\n",
    "            print(f\"EXCEPTION at Piece {piecenum}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        for slice in range(spectrogram.shape[1]):\n",
    "            try:\n",
    "                trueVal = str(int(''.join(map(str, convFilter.getNvec(slice, performance))), 2))\n",
    "                trueSpec = convFilter.getSpectrogram(slice, performance)\n",
    "                \n",
    "                if trueVal in class_count:\n",
    "                    class_count[trueVal] += 1\n",
    "                else:\n",
    "                    class_count[trueVal] = 1\n",
    "                data_count += 1\n",
    "                \n",
    "                if save:\n",
    "                    addImageToDirectory(trueSpec, f\"img{class_count[trueVal]}.png\", trueVal, all_root)\n",
    "                \n",
    "            except IndexError as e:\n",
    "                print(f\"INDEXERROR: PieceNum: {piecenum}, Slice: {slice}, Message: {e}\")    \n",
    "    \n",
    "    print(f\"Total Classes: {len(class_count)}\")\n",
    "    print(f\"Total Data: {data_count}\")\n",
    "            \n",
    "def addImageToDirectory(image, imageName, folder, root):\n",
    "    \"\"\"\n",
    "    Adds image to directory specified\n",
    "    \"\"\"\n",
    "    class_root = os.path.join(root, folder)\n",
    "    if os.path.isdir(class_root):\n",
    "        cv2.imwrite(os.path.join(class_root, imageName), image)\n",
    "    else:\n",
    "        try:  \n",
    "            os.mkdir(class_root)  \n",
    "            cv2.imwrite(os.path.join(class_root, imageName), image)\n",
    "        except OSError as error:  \n",
    "            print(error)\n",
    "\n",
    "def divideDataIntoTrainValTestSets(data_root, train=.6, val=.2, test=.2):\n",
    "    \"\"\"\n",
    "    Distributes data into train, validation, and test sets from all/all folder\n",
    "    \"\"\"\n",
    "    all_root = os.path.join(data_root, \"all/all\")\n",
    "    \n",
    "    assert train + val + test == 1\n",
    "    \n",
    "    split_folders.ratio(all_root, output=data_root, seed=1337, ratio=(train, val, test)) # default values\n",
    "    os.rename(os.path.join(data_root, \"val\"), os.path.join(data_root, \"validation\"))\n",
    "    \n",
    "    temp = \"Temp\"\n",
    "    os.mkdir(os.path.join(data_root, \"train\" + temp))\n",
    "    os.mkdir(os.path.join(data_root, \"validation\" + temp))\n",
    "    os.mkdir(os.path.join(data_root, \"test\" + temp))\n",
    "    \n",
    "    for item in [\"train\", \"validation\", \"test\"]:\n",
    "        dest = shutil.move(os.path.join(data_root, item), os.path.join(data_root, item + temp))\n",
    "        os.rename(os.path.join(data_root, item + temp), os.path.join(data_root, item))\n",
    "        \n",
    "def genNPY(filtered_performances, dataRoot: str):\n",
    "    \"\"\"\n",
    "    Generate the numpy files for all compiled spectrogram and midi data.\n",
    "    Requires npyversion folder to be made inside of data_root foler.\n",
    "    filtered_performances: all performances that have spectrogram and midi data available\n",
    "    dataRoot(str): path to data_root folder.\n",
    "    \"\"\"\n",
    "    piece = filtered_performances[0]\n",
    "    performance = piece.load_performance(piece.available_performances[0], require_audio=False)\n",
    "    all_spectro = performance.load_spectrogram() #loads first spectrogram numpy array to concatenate data to\n",
    "    all_midi = performance.load_midi_matrix() #loads first midi numpy array to concatenate data to\n",
    "\n",
    "    for piece_num in range(1, len(filtered_performances)):\n",
    "        if(piece_num % 30 == 0): print('Piece %d of %d' % (piece_num,len(filtered_performances)))\n",
    "        temp_piece = filtered_performances[piece_num]\n",
    "        temp_performance = temp_piece.load_performance(temp_piece.available_performances[0], require_audio=False)\n",
    "        try:\n",
    "            temp_spectro = temp_performance.load_spectrogram() #loads next spectrogram data\n",
    "            temp_midi = temp_performance.load_midi_matrix() #loads next midi data\n",
    "        except:\n",
    "            continue #no spectrogram data or midi data present for current performance\n",
    "        if(temp_spectro.shape[1] > temp_midi.shape[1]): #spectrogram data is longer length than midi data\n",
    "            all_spectro = np.concatenate((all_spectro, temp_spectro[:,:temp_midi.shape[1]]), axis=1)\n",
    "            all_midi = np.concatenate((all_midi, temp_midi), axis=1)\n",
    "        else: #midi data is longer length than spectrogram data\n",
    "            all_spectro = np.concatenate((all_spectro, temp_spectro), axis=1)\n",
    "            all_midi = np.concatenate((all_midi, temp_midi[:,:temp_spectro.shape[1]]), axis=1)\n",
    "\n",
    "    np.save(dataRoot+'/npyversion/all_spectro.npy', all_spectro) #saving spectrogram numpy file\n",
    "    np.save(dataRoot+'/npyversion/all_midi.npy', all_midi) #saving midi numpy file\n",
    "    return all_spectro, all_midi\n",
    "\n",
    "def genSplitNPY(spectro, midi, dataRoot):\n",
    "    \"\"\"\n",
    "    Generate the numpy files for all compiled spectrogram and midi data split into training,validation, and test.\n",
    "    Split is 60% training, 20% validation, 20% test.\n",
    "    Requires npyversion folder to be made inside of data_root foler.\n",
    "    spectro: numpy array filled with all spectrogram data\n",
    "    midi: numpy array filled with all midi data\n",
    "    dataRoot(str): path to data_root folder.\n",
    "    \"\"\"\n",
    "    length=spectro.shape[1]\n",
    "    idx = np.random.choice(range(length), length, replace=False)\n",
    "    train = idx[:918259]\n",
    "    val = idx[918259:1224345]\n",
    "    test = idx[1224345:length] #60% train, 20% val, 20% test\n",
    "\n",
    "    ################\n",
    "    #Training Split#\n",
    "    ################\n",
    "    train_spectro = np.empty([92,0], dtype=np.float32) #empty training spectrogram array to concatenate to\n",
    "    train_midi = np.empty([128,0], dtype=np.uint8) #empty training midi array to concatenate to\n",
    "    for batch in range(92): #split data into batches to speed up concatenation\n",
    "        if batch != 91: batch_len = 10000 \n",
    "        else: batch_len = 8259 #very last batch of data\n",
    "        temp_spectro1 = np.empty([92,0], dtype=np.float32)\n",
    "        temp_midi1 = np.empty([128,0], dtype=np.uint8)\n",
    "        for idx in range(batch_len):\n",
    "            index = (batch*10000)+idx\n",
    "            temp_spectro2 = spectro[:,train[index]].reshape((92,1))\n",
    "            temp_midi2 = midi[:,train[index]].reshape((128,1))\n",
    "            temp_spectro1 = np.concatenate((temp_spectro1, temp_spectro2), axis=1) #append temp spectrogram data to training\n",
    "            temp_midi1 = np.concatenate((temp_midi1, temp_midi2), axis=1) #append temp midi data to training\n",
    "        train_spectro = np.concatenate((train_spectro, temp_spectro1), axis=1)\n",
    "        train_midi = np.concatenate((train_midi, temp_midi1), axis=1)\n",
    "        print('Batch %d complete' % batch)\n",
    "    np.save(dataRoot+'/npyversion/train_spectro.npy', train_spectro) #save training split spectrogram numpy file\n",
    "    np.save(dataRoot+'/npyversion/train_midi.npy', train_midi) #save training split midi numpy file\n",
    "    print('Training split complete')\n",
    "    \n",
    "    ##################\n",
    "    #Validation Split#\n",
    "    ##################\n",
    "    val_spectro = np.empty([92,0], dtype=np.float32)\n",
    "    val_midi = np.empty([128,0], dtype=np.uint8)\n",
    "    for batch in range(31):\n",
    "        if batch != 30: batch_len = 10000\n",
    "        else: batch_len = 6086\n",
    "        temp_spectro1 = np.empty([92,0], dtype=np.float32)\n",
    "        temp_midi1 = np.empty([128,0], dtype=np.uint8)\n",
    "        for idx in range(batch_len):\n",
    "            index = (batch*10000)+idx\n",
    "            temp_spectro2 = spectro[:,val[index]].reshape((92,1))\n",
    "            temp_midi2 = midi[:,val[index]].reshape((128,1))\n",
    "            temp_spectro1 = np.concatenate((temp_spectro1, temp_spectro2), axis=1)\n",
    "            temp_midi1 = np.concatenate((temp_midi1, temp_midi2), axis=1)\n",
    "        val_spectro = np.concatenate((val_spectro, temp_spectro1), axis=1)\n",
    "        val_midi = np.concatenate((val_midi, temp_midi1), axis=1)\n",
    "        print('Batch %d complete' % batch)\n",
    "    np.save(dataRoot+'/npyversion/val_spectro.npy', val_spectro)\n",
    "    np.save(dataRoot+'/npyversion/val_midi.npy', val_midi)\n",
    "    print('Validation split complete')\n",
    "    \n",
    "    ############\n",
    "    #Test Split#\n",
    "    ############\n",
    "    test_spectro = np.empty([92,0], dtype=np.float32)\n",
    "    test_midi = np.empty([128,0], dtype=np.uint8)\n",
    "    for batch in range(31):\n",
    "        if batch != 30: batch_len = 10000\n",
    "        else: batch_len = 6086\n",
    "        temp_spectro1 = np.empty([92,0], dtype=np.float32)\n",
    "        temp_midi1 = np.empty([128,0], dtype=np.uint8)\n",
    "        for idx in range(batch_len):\n",
    "            index = (batch*10000)+idx\n",
    "            temp_spectro2 = spectro[:,test[index]].reshape((92,1))\n",
    "            temp_midi2 = midi[:,test[index]].reshape((128,1))\n",
    "            temp_spectro1 = np.concatenate((temp_spectro1, temp_spectro2), axis=1)\n",
    "            temp_midi1 = np.concatenate((temp_midi1, temp_midi2), axis=1)\n",
    "        test_spectro = np.concatenate((test_spectro, temp_spectro1), axis=1)\n",
    "        test_midi = np.concatenate((test_midi, temp_midi1), axis=1)\n",
    "        print('Batch %d complete' % batch)\n",
    "    np.save(dataRoot+'/npyversion/test_spectro.npy', test_spectro)\n",
    "    np.save(dataRoot+'/npyversion/test_midi.npy', test_midi)\n",
    "    print('Test split complete')\n",
    "\n",
    "def loadAllData(dataRoot: str):\n",
    "    \"\"\"\n",
    "    Loads all spectrogram and all midi data from numpy files.\n",
    "    dataRoot(str): path to data_root folder.\n",
    "    \"\"\"\n",
    "    return np.load(dataRoot+'/npyversion/all_spectro.npy'), np.load(dataRoot+'/npyversion/all_midi.npy')\n",
    "\n",
    "def loadSplitData(dataRoot: str):\n",
    "    \"\"\"\n",
    "    Loads all spectrogram and all midi split data from numpy files.\n",
    "    dataRoot(str): path to data_root folder.\n",
    "    \"\"\"\n",
    "    train = (np.load(dataRoot+'/npyversion/train_spectro.npy'), np.load(dataRoot+'/npyversion/train_midi.npy'))\n",
    "    val = (np.load(dataRoot+'/npyversion/val_spectro.npy'), np.load(dataRoot+'/npyversion/val_midi.npy'))\n",
    "    test = (np.load(dataRoot+'/npyversion/test_spectro.npy'), np.load(dataRoot+'/npyversion/test_midi.npy'))\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes: 35531\n",
      "Total Data: 1530431\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    DATA_ROOT_MSMD = '/Users/gbanuru/PycharmProjects/HACKUCI/msmd_aug_v1-1_no-audio/' # path to MSMD data set\n",
    "    data_root = \"/Users/gbanuru/PycharmProjects/HACKUCI/msmd/tutorials/data_root\" # path to our created dataset  \n",
    "    \n",
    "    #filtered_performances = convFilter.filteredData(DATA_ROOT_MSMD) #creates a list with piece objects\n",
    "    #print(f\"All pieces: {len(filtered_performances)}\")\n",
    "    #populateData(filtered_performances[:], data_root, save = False)\n",
    "    #divideDataIntoTrainValTestSets(data_root)\n",
    "    \n",
    "    countClasses(data_root)\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLEASE CREATE npyversion folder inside data_root folder and change paths to corresponding paths on your system.\n",
    "DATA_ROOT_MSMD = 'C:/msmd_aug/' # path to MSMD data set\n",
    "dataRoot = \"/Users/Calvin/Documents/UCI/COMPSCI/175/msmd/tutorials/data_root\" # path to our created dataset\n",
    "   \n",
    "filtered_performances = convFilter.filteredData(DATA_ROOT_MSMD) #creates a list with piece object\n",
    "\n",
    "spectro, midi = genNPY(filtered_performances, dataRoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro = np.load('/Users/Calvin/Documents/UCI/COMPSCI/175/msmd/tutorials/data_root/npyversion/all_spectro.npy')\n",
    "midi = np.load('/Users/Calvin/Documents/UCI/COMPSCI/175/msmd/tutorials/data_root/npyversion/all_midi.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genSplitNPY(spectro, midi, dataRoot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
